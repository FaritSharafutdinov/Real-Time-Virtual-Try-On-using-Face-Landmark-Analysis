# Real-Time Virtual Try-On using Face Landmark Analysis

Проект представляет собой приложение дополненной реальности (AR) в реальном времени, которое позволяет пользователям виртуально примерять 2D аксессуары, такие как очки или шляпы, используя веб-камеру.

## Описание

Система работает путем захвата видео с веб-камеры, детекции лица пользователя и определения ключевых точек лица. На основе этих точек приложение позиционирует и трансформирует выбранный аксессуар так, чтобы он естественно следовал движениям головы пользователя. Для плавного и реалистичного наложения используются техники геометрического преобразования в сочетании с альфа-блендингом.

## Основные возможности

- ✅ Детекция лица в реальном времени с использованием MediaPipe Face Mesh
- ✅ Определение 468 ключевых точек лица
- ✅ Геометрические преобразования (перспективные и аффинные) для позиционирования аксессуаров
- ✅ Альфа-блендинг для реалистичного наложения
- ✅ Сглаживание для стабильности наложения
- ✅ Переключение между несколькими аксессуарами
- ✅ Поддержка различных типов аксессуаров (очки, шляпы)

## Структура проекта

```
cvp/
├── face_landmark_detector.py    # Модуль детекции лица и landmarks
├── geometric_transformer.py     # Модуль геометрических преобразований
├── accessory_overlay.py          # Модуль наложения и блендинга
├── virtual_tryon_app.py         # Основное приложение
├── create_sample_accessories.py # Скрипт для создания тестовых аксессуаров
├── requirements.txt              # Зависимости проекта
├── accessories/                  # Папка с изображениями аксессуаров (PNG)
└── README.md                     # Документация
```

## Требования

- **Python 3.8 - 3.12** (MediaPipe не поддерживает Python 3.13+)
- Веб-камера
- Windows/Linux/macOS

> **Важно:** Если у вас установлен Python 3.13 или выше, вам нужно использовать Python 3.11 или 3.12. Вы можете:
> - Установить Python 3.11/3.12 параллельно
> - Использовать виртуальное окружение с нужной версией Python
> - Использовать `pyenv` для управления версиями Python

## Установка

1. **Проверьте версию Python:**
   ```bash
   python --version
   ```
   Должна быть версия от 3.8 до 3.12 включительно.

2. **Обновите pip (рекомендуется):**
   ```bash
   python -m pip install --upgrade pip
   ```

3. **Установите зависимости:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Создайте тестовые аксессуары (опционально):**
   ```bash
   python create_sample_accessories.py
   ```
   
   Это создаст папку `accessories/` с примерами аксессуаров (очки, солнцезащитные очки, шляпа).

4. **Добавьте свои аксессуары (опционально):**
   
   Поместите PNG файлы с прозрачным фоном в папку `accessories/`. 
   - Для очков: используйте имя файла с "glasses" в названии
   - Для шляп: используйте имя файла с "hat" или "cap" в названии
   
   Примеры: `my_glasses.png`, `cool_hat.png`, `sunglasses.png`

## Использование

Запустите основное приложение:

```bash
python virtual_tryon_app.py
```

### Управление

- **'n' или 'N'** - Следующий аксессуар
- **'p' или 'P'** - Предыдущий аксессуар
- **'s' или 'S'** - Переключить сглаживание (высокое/низкое)
- **'q' или ESC** - Выход из приложения

### Требования к аксессуарам

- Формат: PNG с альфа-каналом (прозрачный фон)
- Рекомендуемый размер: 300-500 пикселей по ширине
- Аксессуар должен быть ориентирован правильно (очки горизонтально, шляпа сверху)

## Технические детали

### Архитектура

Проект состоит из четырех основных модулей:

1. **FaceLandmarkDetector** (`face_landmark_detector.py`)
   - Использует MediaPipe Face Mesh для детекции лица
   - Извлекает 468 ключевых точек лица
   - Определяет точки привязки для различных типов аксессуаров

2. **GeometricTransformer** (`geometric_transformer.py`)
   - Вычисляет матрицы преобразования (перспективные и аффинные)
   - Выполняет геометрическое искажение аксессуаров
   - Реализует сглаживание для уменьшения дрожания

3. **AccessoryOverlay** (`accessory_overlay.py`)
   - Загружает изображения аксессуаров
   - Выполняет альфа-блендинг
   - Накладывает аксессуары на видео-кадры

4. **VirtualTryOnApp** (`virtual_tryon_app.py`)
   - Интегрирует все модули
   - Управляет видеопотоком с веб-камеры
   - Обрабатывает пользовательский ввод

### Методология

Система следует четырехэтапному пайплайну для каждого кадра видео:

1. **Детекция лица**: MediaPipe Face Mesh обнаруживает лицо в видеопотоке
2. **Определение landmarks**: Извлекаются ключевые точки лица (глаза, нос, рот)
3. **Геометрическое преобразование**: Вычисляется матрица преобразования на основе опорных точек аксессуара и соответствующих точек лица
4. **Наложение и блендинг**: Аксессуар искажается согласно матрице и накладывается на кадр с использованием альфа-блендинга

### Используемые технологии

- **OpenCV** - Обработка изображений и видео
- **MediaPipe** - Детекция лица и определение landmarks
- **NumPy** - Математические операции и работа с массивами

## Производительность

- **FPS**: Приложение выводит FPS каждые 30 кадров в консоль
- **Оптимизация**: Используется сглаживание для стабильности наложения
- **Требования**: Современная веб-камера и процессор средней мощности

## Будущие улучшения

- [ ] Поддержка нескольких лиц одновременно
- [ ] Более точное позиционирование для различных типов аксессуаров
- [ ] Регулировка размера аксессуаров в реальном времени
- [ ] Сохранение скриншотов с наложенными аксессуарами
- [ ] Графический интерфейс (GUI) вместо консольного управления

## Авторы

- Farit Sharafutdinov (f.sharafutdinov@innopolis.university)
- Grigorii Belyaev (g.belyaev@innopolis.university)

B23 - AI01, Innopolis University

## Лицензия

Этот проект создан в образовательных целях.

## Ссылки

- [OpenCV Documentation](https://docs.opencv.org/)
- [MediaPipe Face Mesh](https://google.github.io/mediapipe/solutions/face_mesh.html)
- [Computer Vision: Algorithms and Applications](https://szeliski.org/Book/)

